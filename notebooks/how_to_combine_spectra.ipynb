{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zJgAlhEZEEu"
   },
   "source": [
    "# How to combine spectra without interpolation.\n",
    "\n",
    "A notebook to support and illustrate ideas in a forthcoming paper.\n",
    "\n",
    "## Authors:\n",
    "- **David W Hogg** (NYU) (MPIA) (Flatiron)\n",
    "- **Andy Casey** (Monash)\n",
    "\n",
    "## To-Do:\n",
    "- Define three data sets (good sampling, bad sampling, very bad sampling).\n",
    "- Output plots for the paper as PNG or PDF and git commit them.\n",
    "- Maybe add residual plots to the combined-spectrum plots? They could be added at y=0.\n",
    "- Make a figure that shows dependence of output on input-data pixel spacing.\n",
    "- Make a figure that shows empirical pixel-to-pixel covariances as a function of lag.\n",
    "- These latter two projects require that we turn the *Forward Model (tm)* into one single function call, and we turn *Standard Practice (tm)* into one single function call.\n",
    "\n",
    "## Bugs:\n",
    "- Uses `np.random.seed()` and not a random number generator object.\n",
    "- Sometimes uses `j` where it should use `i`; notation should match the *LaTeX* file!\n",
    "- *Sign* and *name* of *Delta x_i* not used correctly in plots or code.\n",
    "- Currently the text doesn't explain the data generation process quite correctly (it involves an `exp()` call).\n",
    "- Currently the text doesn't explain the additive noise correctly (it involves a flux-expectation-dependent scaling).\n",
    "- Plotting code contains repeated magic numbers.\n",
    "\n",
    "## Comments:\n",
    "- The badness of *Standard Practice (tm)* relative to the *Forward Model (tm)* is a strong function of the sampling of the raw data. Like 0.65 R is way way worse than 0.75 R.\n",
    "\n",
    "## Stretch goals:\n",
    "- Execute on real individual-exposure *SDSS-V APOGEE* data, perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OV2XsTPcZCW1"
   },
   "outputs": [],
   "source": [
    "# imports and initialize seeds, fundamental constants\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import scipy.interpolate as interp\n",
    "np.random.seed(42) # the second-most random number, after 17.\n",
    "c = 299792458. # m / s\n",
    "sqrt2pi = np.sqrt(2. * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5anH7Sfvzget"
   },
   "outputs": [],
   "source": [
    "# plotting defaults\n",
    "# has to be in its own cell?\n",
    "plt.rc('figure', figsize=(6.0, 3.6), dpi=150, autolayout=True)\n",
    "# plt.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUQGCeXhOW0B"
   },
   "source": [
    "## Make a fake data set with `n_epoch` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUui_2CzZefd"
   },
   "outputs": [],
   "source": [
    "# define high-level parameters, especially including spectrograph parameters\n",
    "R = 1.35e5 # resolution\n",
    "SNR = 15. # s/n ratio per pixel in the continuum\n",
    "sigma_x = 1. / R # LSF sigma in x units\n",
    "dx = 1. / (0.7 * R) # pixel spacing in the poorly sampled data; UNDER-SAMPLED!\n",
    "x_min = 8.7000 # minimum ln wavelength\n",
    "x_max = 8.7025 # maximum ln wavelength\n",
    "lines_per_x = 2.0e4 # mean density (Poisson rate) of lines per unit ln wavelength\n",
    "ew_max_x = 3.0e-5 # maximum equivalent width in x units\n",
    "ew_power = 5.0 # power parameter in EW maker\n",
    "badfrac = 0.01 # fraction of data to mark bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rW768X-atC4"
   },
   "outputs": [],
   "source": [
    "# set up the line list for the true spectral model\n",
    "x_margin = 1.e6/c # hoping no velocities are bigger than 1000 km/s\n",
    "x_range = x_max - x_min + 2. * x_margin # make lines in a bigger x range than the data range\n",
    "nlines = np.random.poisson(x_range * lines_per_x) # set the total number of lines\n",
    "line_xs = (x_min - x_margin) + x_range * np.random.uniform(size=nlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIV0InZCe7SI"
   },
   "outputs": [],
   "source": [
    "# give those lines equivalent widths from a power-law distribution\n",
    "line_ews = ew_max_x * np.random.uniform(size=nlines) ** ew_power # don't ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S11G274KbgVC"
   },
   "outputs": [],
   "source": [
    "# make the synthetic spectrum (spectral expectation), and also add noise\n",
    "\n",
    "def oned_gaussian(dxs, sigma):\n",
    "    return np.exp(-0.5 * dxs ** 2 / sigma ** 2) / (sqrt2pi * sigma)\n",
    "\n",
    "def true_spectrum(xs, doppler, lxs=line_xs, ews=line_ews, sigma=sigma_x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return np.exp(-1. * np.sum(ews[None, :] *\n",
    "                               oned_gaussian(xs[:, None] - doppler\n",
    "                                             - lxs[None, :], sigma), axis=1))\n",
    "\n",
    "def ivar(ys, continuum_ivar):\n",
    "    return continuum_ivar / ys\n",
    "\n",
    "def noisy_true_spectrum(xs, doppler, continuum_ivar):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ys_true = true_spectrum(xs, doppler)\n",
    "    y_ivars = ivar(ys_true, continuum_ivar)\n",
    "    return  ys_true + np.random.normal(size=xs.shape) / np.sqrt(y_ivars), y_ivars\n",
    "\n",
    "def doppler_information(xs, doppler, continuum_ivar, dx=0.5*dx):\n",
    "    \"\"\"\n",
    "    # Bugs:\n",
    "    - Horrifying numerical derivative!\n",
    "    \"\"\"\n",
    "    dys_dx = (true_spectrum(xs, doppler + dx)\n",
    "              - true_spectrum(xs, doppler - dx)) / (2. * dx)\n",
    "    y_ivars = ivar(true_spectrum(xs, doppler), continuum_ivar)\n",
    "    return np.sum(y_ivars * dys_dx ** 2)\n",
    "\n",
    "def badify(yy):\n",
    "    \"\"\"\n",
    "    Make bad-pixel masks and badify the bad pixels.\n",
    "    \"\"\"\n",
    "    bady = 1. * yy\n",
    "    bs = (np.random.uniform(size=len(bady)) > badfrac).astype(int)\n",
    "    bs = np.minimum(bs, np.roll(bs, 1))\n",
    "    bs = np.minimum(bs, np.roll(bs, -1))\n",
    "    nbad = np.sum(bs < 0.5)\n",
    "    if nbad > 0:\n",
    "        bady[bs < 0.5] += 2. * np.random.uniform(size=nbad)\n",
    "    return bs, bady\n",
    "\n",
    "def make_one_dataset(n_epochs=16, dx=dx, SNR=SNR):\n",
    "    # create true Doppler shifts on a sinusoid of epoch number\n",
    "    Delta_xs = (3.e4 / c) * np.cos(np.arange(n_epochs) / 3)\n",
    "    # set the ivar\n",
    "    continuum_ivar = SNR ** 2 # inverse variance of the noise in the continuum\n",
    "    # now make the noisy fake data\n",
    "    xs = np.arange(x_min, x_max, dx) # pixel grid for single-epoch observations\n",
    "    ys = np.zeros((n_epochs, len(xs)))\n",
    "    y_ivars = np.zeros_like(ys)\n",
    "    bs = np.zeros_like(ys).astype(int)\n",
    "    for j in range(n_epochs):\n",
    "        ys[j], y_ivars[j] = noisy_true_spectrum(xs, Delta_xs[j], continuum_ivar)\n",
    "        bs[j], ys[j] = badify(ys[j])\n",
    "    return xs, ys, y_ivars, bs, Delta_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys, y_ivars, bs, Delta_xs = make_one_dataset()\n",
    "M = len(xs)\n",
    "n_epochs = len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cwr9Gc19dpcL"
   },
   "outputs": [],
   "source": [
    "# show the input data\n",
    "fig, axes = plt.subplots(n_epochs // 2, 2, sharex=True, sharey=True,\n",
    "                         figsize=(12., 0.75 * n_epochs))\n",
    "for j,ax in enumerate(axes.flatten()):\n",
    "    ax.step(xs, ys[j], color=\"k\", where=\"mid\", alpha=0.9)\n",
    "    ax.set_title(\"epoch {}; $\\Delta x = {:+f}$\".format(j + 1, Delta_xs[j]))\n",
    "    ax.set_ylabel(r\"flux $y$\")\n",
    "    for k in np.arange(len(ys[j]))[bs[j] < 0.5]:\n",
    "        ax.fill_between([xs[k] - 0.5 * dx, xs[k] + 0.5 * dx],\n",
    "                        [0., 0.], [2., 2.], color=\"k\", alpha=0.25, ec=\"none\")\n",
    "for j in range(2):\n",
    "    axes[-1, j].set_xlabel(r\"ln wavelength $x=\\ln\\,\\lambda$\")\n",
    "plt.xlim(x_min, x_max)\n",
    "ylim = (0.1, 1.2)\n",
    "plt.ylim(*ylim)\n",
    "plt.savefig(\"data.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8o7u_sfMdyfl"
   },
   "outputs": [],
   "source": [
    "# zoom in on one epoch and compare it to the true template.\n",
    "j = 6\n",
    "fig, axes = plt.subplots(2, 1, sharex=False, sharey=True)\n",
    "finexs = np.arange(np.min(xs), np.max(xs), 1. / (5. * R))\n",
    "for ax in axes:\n",
    "    ax.step(xs, ys[j], color=\"k\", where=\"mid\", alpha=0.9)\n",
    "    ax.set_ylabel(r\"flux $y$\")\n",
    "    ax.plot(finexs, true_spectrum(finexs, 0.), \"r-\", alpha=1.0, lw=0.5)\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "    for k in np.arange(len(ys[j]))[bs[j] < 0.5]:\n",
    "        ax.fill_between([xs[k] - 0.5 * dx, xs[k] + 0.5 * dx],\n",
    "                        [-1., -1.], [2., 2.], color=\"k\", alpha=0.25, ec=\"none\")\n",
    "\n",
    "axes[0].set_xlim(8.7000, 8.70125)\n",
    "axes[1].set_xlim(8.70125, 8.7025)\n",
    "axes[0].set_ylim(*ylim)\n",
    "axes[1].set_xlabel(r\"ln wavelength $x=\\ln\\,\\lambda$\")\n",
    "axes[0].set_title(\"epoch {}; $\\Delta x = {:+f}$\".format(j + 1, Delta_xs[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqrPw48tOhIO"
   },
   "source": [
    "## Set up output parameters and functions for combined spectrum.\n",
    "\n",
    "Notes:\n",
    "- If you set `P = Mstar` then the Fourier model can interpolate anything.\n",
    "- If you set `P = Mstar // 2 + 1` then the Fourier model will be band-limited at the Nyquist frequency. This is cool but it shows ringing / wiggles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8TN5UDwhv2E"
   },
   "outputs": [],
   "source": [
    "def design_matrix(xs, P, L=(x_max - x_min)):\n",
    "    \"\"\"\n",
    "    Take in a set of x positions and return the Fourier design matrix.\n",
    "\n",
    "    ## Bugs:\n",
    "    - Needs comment header.\n",
    "    \n",
    "    ## Comments:\n",
    "    - The code looks different from the paper because Python zero-indexes.\n",
    "    - This could be replaced with something that makes use of finufft.\n",
    "    \"\"\"\n",
    "    X = np.ones_like(xs).reshape(len(xs), 1)\n",
    "    for j in range(1, P):\n",
    "        if j % 2 == 0:\n",
    "            X = np.concatenate((X, np.cos(np.pi * j * xs / L)[:, None]), axis=1)\n",
    "        else:\n",
    "            X = np.concatenate((X, np.sin(np.pi * (j + 1) * xs / L)[:, None]), axis=1)\n",
    "    return X\n",
    "\n",
    "def pack_matrices(xs, ys, bs, Delta_xs, P):\n",
    "    \"\"\"\n",
    "    Rearrange data into big matrices for `lstsq()`.\n",
    "\n",
    "    ## Bugs:\n",
    "    - Needs comment header.\n",
    "    \"\"\"\n",
    "    XX = np.array([])\n",
    "    YY = np.array([])\n",
    "    for bb, yy, Dx in zip(bs, ys, Delta_xs):\n",
    "        x_rest = (xs - Dx)[bb > 0.5]\n",
    "        I = np.logical_and(x_rest > x_min, x_rest < x_max)\n",
    "        YY = np.append(YY, yy[bb > 0.5][I])\n",
    "        XX = np.append(XX, x_rest[I])\n",
    "    return design_matrix(XX, P), YY\n",
    "\n",
    "def Forward_Model_tm(xs, ys, bs, Delta_xs, P, xstar):\n",
    "    \"\"\"\n",
    "    Do it all!\n",
    "    \n",
    "    ## Bugs:\n",
    "    - Doesn't take the inverse variance on the data!\n",
    "    - Doesn't return the inverse variance tensor for the output.\n",
    "    \"\"\"\n",
    "    X, Y = pack_matrices(xs, ys, bs, Delta_xs, P)\n",
    "    Xstar = design_matrix(xstar, P)\n",
    "    thetahat, foo, bar, whatevs = np.linalg.lstsq(X, Y, rcond=None)\n",
    "    return Xstar @ thetahat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZI7OOvgOoH2"
   },
   "source": [
    "## Make the combined spectrum and compare to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zmz6ig44cSb0"
   },
   "outputs": [],
   "source": [
    "# Set the pixel grid and model complexity for the combined spectrum\n",
    "dxstar = 1. / (1.2 * R) # output pixel grid spacing\n",
    "xstar = np.arange(x_min - 1.5 * dxstar, x_max + 2.0 * dxstar, dxstar) # output pixel grid\n",
    "Mstar = len(xstar) # number of output pixels\n",
    "P = Mstar # number of Fourier modes (ish)\n",
    "print(Mstar, P, xstar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ForP6tkul2_7"
   },
   "outputs": [],
   "source": [
    "ystar = Forward_Model_tm(xs, ys, bs, Delta_xs, P, xstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOxaEZvdmoP4"
   },
   "outputs": [],
   "source": [
    "# compare the combined spectrum to the true template.\n",
    "fig, axes = plt.subplots(2, 1, sharex=False, sharey=True)\n",
    "for ax in axes:\n",
    "    ax.step(xstar, ystar, color=\"k\", where=\"mid\", alpha=0.9)\n",
    "    ax.set_ylabel(r\"flux $y$\")\n",
    "    ax.plot(finexs, true_spectrum(finexs, 0.), \"r-\", alpha=1.0, lw=0.5)\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "axes[0].set_xlim(8.7000, 8.70125)\n",
    "axes[1].set_xlim(8.70125, 8.7025)\n",
    "axes[0].set_ylim(*ylim)\n",
    "axes[1].set_xlabel(r\"ln wavelength $x=\\ln\\,\\lambda$\")\n",
    "axes[0].set_title(\"Forward Model (tm) combined spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff-5udYpnaCj"
   },
   "source": [
    "## Implement a version of *Standard Practice (tm)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standard_Practice_tm(xs, ys, bs, Delta_xs, xstar, kind=\"cubic\"):\n",
    "    #interpolate the data and the masks; deal with edges.\n",
    "    # Note that we are being very conservative with the mask.\n",
    "    yprimes = np.zeros((n_epochs, len(xstar)))\n",
    "    bprimes = np.zeros_like(yprimes).astype(int)\n",
    "    ikwargs = {\"kind\": kind, \"fill_value\": \"extrapolate\"}\n",
    "    for j in range(n_epochs):\n",
    "        yprimes[j] = interp.interp1d(xs - Delta_xs[j], ys[j],\n",
    "                                     **ikwargs)(xstar)\n",
    "        bprimes[j] = (np.abs(interp.interp1d(xs - Delta_xs[j], bs[j],\n",
    "                                     **ikwargs)(xstar) - 1.) < 0.01).astype(int)\n",
    "        bprimes[j][xstar < (min(xs) - Delta_xs[j])] = 0\n",
    "        bprimes[j][xstar > (max(xs) - Delta_xs[j])] = 0\n",
    "    ystar = np.sum(yprimes * bprimes, axis=0) / np.sum(bprimes, axis=0)\n",
    "    return ystar, yprimes, bprimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the combination\n",
    "ystar_sp, yprimes, bprimes = Standard_Practice_tm(xs, ys, bs, Delta_xs, xstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 6\n",
    "fig, axes = plt.subplots(2, 1, sharex=False, sharey=True)\n",
    "for ax in axes:\n",
    "    ax.step(xstar, yprimes[j], color=\"k\", where=\"mid\", alpha=0.9)\n",
    "    ax.set_ylabel(r\"flux $y$\")\n",
    "    ax.plot(finexs, true_spectrum(finexs, 0.), \"r-\", alpha=1.0, lw=0.5)\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "    for k in np.arange(len(yprimes[j]))[bprimes[j] < 0.5]:\n",
    "        ax.fill_between([xstar[k] - 0.5 * dxstar, xstar[k] + 0.5 * dxstar],\n",
    "                        [0., 0.], [2., 2.], color=\"k\", alpha=0.25, ec=\"none\")\n",
    "axes[0].set_xlim(8.7000, 8.70125)\n",
    "axes[1].set_xlim(8.70125, 8.7025)\n",
    "axes[0].set_ylim(*ylim)\n",
    "axes[1].set_xlabel(r\"ln wavelength $x=\\ln\\,\\lambda$\")\n",
    "axes[0].set_title(\"epoch {}, interpolated to rest frame\".format(j + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the combined spectrum to the true template.\n",
    "fig, axes = plt.subplots(2, 1, sharex=False, sharey=True)\n",
    "for ax in axes:\n",
    "    ax.step(xstar, ystar_sp, color=\"k\", where=\"mid\", alpha=0.9)\n",
    "    ax.set_ylabel(r\"flux $y$\")\n",
    "    ax.plot(finexs, true_spectrum(finexs, 0.), \"r-\", alpha=1.0, lw=0.5)\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "axes[0].set_xlim(8.7000, 8.70125)\n",
    "axes[1].set_xlim(8.70125, 8.7025)\n",
    "axes[0].set_ylim(*ylim)\n",
    "axes[1].set_xlabel(r\"ln wavelength $x=\\ln\\,\\lambda$\")\n",
    "axes[0].set_title(\"Standard Practice (tm) combined spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Make results as a function of input-data pixel scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Empirically compute pixel covariances as a function of lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6hz1itYgMrK63Yu2plb9t",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
