{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire module is from SpecRes by A C Carnall\n",
    "# https://ui.adsabs.harvard.edu/abs/2017arXiv170505165C/abstract\n",
    "\n",
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_bins(wavs):\n",
    "    \"\"\" Given a series of wavelength points, find the edges and widths\n",
    "    of corresponding wavelength bins. \"\"\"\n",
    "    edges = np.zeros(wavs.shape[0]+1)\n",
    "    widths = np.zeros(wavs.shape[0])\n",
    "    edges[0] = wavs[0] - (wavs[1] - wavs[0])/2\n",
    "    widths[-1] = (wavs[-1] - wavs[-2])\n",
    "    edges[-1] = wavs[-1] + (wavs[-1] - wavs[-2])/2\n",
    "    edges[1:-1] = (wavs[1:] + wavs[:-1])/2\n",
    "    widths[:-1] = edges[1:-1] - edges[:-2]\n",
    "\n",
    "    return edges, widths\n",
    "\n",
    "\n",
    "def spectres(new_wavs, spec_wavs, spec_fluxes, spec_errs=None, fill=None,\n",
    "             verbose=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Function for resampling spectra (and optionally associated\n",
    "    uncertainties) onto a new wavelength basis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    new_wavs : numpy.ndarray\n",
    "        Array containing the new wavelength sampling desired for the\n",
    "        spectrum or spectra.\n",
    "\n",
    "    spec_wavs : numpy.ndarray\n",
    "        1D array containing the current wavelength sampling of the\n",
    "        spectrum or spectra.\n",
    "\n",
    "    spec_fluxes : numpy.ndarray\n",
    "        Array containing spectral fluxes at the wavelengths specified in\n",
    "        spec_wavs, last dimension must correspond to the shape of\n",
    "        spec_wavs. Extra dimensions before this may be used to include\n",
    "        multiple spectra.\n",
    "\n",
    "    spec_errs : numpy.ndarray (optional)\n",
    "        Array of the same shape as spec_fluxes containing uncertainties\n",
    "        associated with each spectral flux value.\n",
    "\n",
    "    fill : float (optional)\n",
    "        Where new_wavs extends outside the wavelength range in spec_wavs\n",
    "        this value will be used as a filler in new_fluxes and new_errs.\n",
    "\n",
    "    verbose : bool (optional)\n",
    "        Setting verbose to False will suppress the default warning about\n",
    "        new_wavs extending outside spec_wavs and \"fill\" being used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    new_fluxes : numpy.ndarray\n",
    "        Array of resampled flux values, first dimension is the same\n",
    "        length as new_wavs, other dimensions are the same as\n",
    "        spec_fluxes.\n",
    "\n",
    "    new_errs : numpy.ndarray\n",
    "        Array of uncertainties associated with fluxes in new_fluxes.\n",
    "        Only returned if spec_errs was specified.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename the input variables for clarity within the function.\n",
    "    old_wavs = spec_wavs\n",
    "    old_fluxes = spec_fluxes\n",
    "    old_errs = spec_errs\n",
    "\n",
    "    # Make arrays of edge positions and widths for the old and new bins\n",
    "\n",
    "    old_edges, old_widths = make_bins(old_wavs)\n",
    "    new_edges, new_widths = make_bins(new_wavs)\n",
    "\n",
    "    # Generate output arrays to be populated\n",
    "    new_fluxes = np.zeros(old_fluxes[..., 0].shape + new_wavs.shape)\n",
    "\n",
    "    if old_errs is not None:\n",
    "        if old_errs.shape != old_fluxes.shape:\n",
    "            raise ValueError(\"If specified, spec_errs must be the same shape \"\n",
    "                             \"as spec_fluxes.\")\n",
    "        else:\n",
    "            new_errs = np.copy(new_fluxes)\n",
    "\n",
    "    start = 0\n",
    "    stop = 0\n",
    "    warned = False\n",
    "\n",
    "    # Calculate new flux and uncertainty values, looping over new bins\n",
    "    for j in range(new_wavs.shape[0]):\n",
    "\n",
    "        # Add filler values if new_wavs extends outside of spec_wavs\n",
    "        if (new_edges[j] < old_edges[0]) or (new_edges[j+1] > old_edges[-1]):\n",
    "            new_fluxes[..., j] = fill\n",
    "\n",
    "            if spec_errs is not None:\n",
    "                new_errs[..., j] = fill\n",
    "\n",
    "            if (j == 0 or j == new_wavs.shape[0]-1) and verbose and not warned:\n",
    "                warned = True\n",
    "                print(\"\\nSpectres: new_wavs contains values outside the range \"\n",
    "                      \"in spec_wavs, new_fluxes and new_errs will be filled \"\n",
    "                      \"with the value set in the 'fill' keyword argument. \\n\")\n",
    "            continue\n",
    "\n",
    "        # Find first old bin which is partially covered by the new bin\n",
    "        while old_edges[start+1] <= new_edges[j]:\n",
    "            start += 1\n",
    "\n",
    "        # Find last old bin which is partially covered by the new bin\n",
    "        while old_edges[stop+1] < new_edges[j+1]:\n",
    "            stop += 1\n",
    "\n",
    "        # If new bin is fully inside an old bin start and stop are equal\n",
    "        if stop == start:\n",
    "            new_fluxes[..., j] = old_fluxes[..., start]\n",
    "            if old_errs is not None:\n",
    "                new_errs[..., j] = old_errs[..., start]\n",
    "\n",
    "        # Otherwise multiply the first and last old bin widths by P_ij\n",
    "        else:\n",
    "            start_factor = ((old_edges[start+1] - new_edges[j])\n",
    "                            / (old_edges[start+1] - old_edges[start]))\n",
    "\n",
    "            end_factor = ((new_edges[j+1] - old_edges[stop])\n",
    "                          / (old_edges[stop+1] - old_edges[stop]))\n",
    "\n",
    "            old_widths[start] *= start_factor\n",
    "            old_widths[stop] *= end_factor\n",
    "\n",
    "            # Populate new_fluxes spectrum and uncertainty arrays\n",
    "            f_widths = old_widths[start:stop+1]*old_fluxes[..., start:stop+1]\n",
    "            new_fluxes[..., j] = np.sum(f_widths, axis=-1)\n",
    "            new_fluxes[..., j] /= np.sum(old_widths[start:stop+1])\n",
    "\n",
    "            if old_errs is not None:\n",
    "                e_wid = old_widths[start:stop+1]*old_errs[..., start:stop+1]\n",
    "\n",
    "                new_errs[..., j] = np.sqrt(np.sum(e_wid**2, axis=-1))\n",
    "                new_errs[..., j] /= np.sum(old_widths[start:stop+1])\n",
    "\n",
    "            # Put back the old bin widths to their initial values\n",
    "            old_widths[start] /= start_factor\n",
    "            old_widths[stop] /= end_factor\n",
    "\n",
    "    # If errors were supplied return both new_fluxes and new_errs.\n",
    "    if old_errs is not None:\n",
    "        return new_fluxes, new_errs\n",
    "\n",
    "    # Otherwise just return the new_fluxes spectrum array\n",
    "    else:\n",
    "        return new_fluxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and initialize seeds, fundamental constants\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(17)\n",
    "c = 299792458. # m / s\n",
    "sqrt2pi = np.sqrt(2. * np.pi)\n",
    "\n",
    "from ndi import resample_spectrum\n",
    "\n",
    "# make the synthetic spectrum (spectral expectation), and also add noise\n",
    "\n",
    "def oned_gaussian(dxs, sigma):\n",
    "    return np.exp(-0.5 * dxs ** 2 / sigma ** 2) / (sqrt2pi * sigma)\n",
    "\n",
    "def true_spectrum(xs, doppler, lxs, ews, sigma):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return np.exp(-1. * np.sum(ews[None, :] *\n",
    "                               oned_gaussian(xs[:, None] - doppler\n",
    "                                             - lxs[None, :], sigma), axis=1))\n",
    "\n",
    "def ivar(ys, continuum_ivar):\n",
    "    return continuum_ivar / ys\n",
    "\n",
    "def noisy_true_spectrum(xs, doppler, continuum_ivar, line_xs, line_ews, sigma_x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ys_true = true_spectrum(xs, doppler, line_xs, line_ews, sigma_x)\n",
    "    y_ivars = ivar(ys_true, continuum_ivar)\n",
    "    return  (ys_true + np.random.normal(size=xs.shape) / np.sqrt(y_ivars), y_ivars)\n",
    "\n",
    "def doppler_information(xs, doppler, continuum_ivar, dx):\n",
    "    \"\"\"\n",
    "    # Bugs:\n",
    "    - Horrifying numerical derivative!\n",
    "    \"\"\"\n",
    "    dys_dx = (true_spectrum(xs, doppler + dx)\n",
    "              - true_spectrum(xs, doppler - dx)) / (2. * dx)\n",
    "    y_ivars = ivar(true_spectrum(xs, doppler), continuum_ivar)\n",
    "    return np.sum(y_ivars * dys_dx ** 2)\n",
    "\n",
    "def badify(yy, badfrac):\n",
    "    \"\"\"\n",
    "    Make bad-pixel masks and badify the bad pixels.\n",
    "    \"\"\"\n",
    "    bady = 1. * yy\n",
    "    bs = (np.random.uniform(size=len(bady)) > badfrac).astype(int)\n",
    "    bs = np.minimum(bs, np.roll(bs, 1))\n",
    "    bs = np.minimum(bs, np.roll(bs, -1))\n",
    "    nbad = np.sum(bs < 0.5)\n",
    "    if nbad > 0:\n",
    "        bady[bs < 0.5] += 2. * np.random.uniform(size=nbad)\n",
    "    return bs, bady\n",
    "\n",
    "def make_one_dataset(dx, SNR, x_min, x_max, line_xs, line_ews, sigma_x, badfrac, xstar, N=8):\n",
    "    # create true Doppler shifts on a sinusoid of epoch number\n",
    "    Delta_xs = (3.e4 / c) * np.cos(np.arange(N) / 3.)\n",
    "    # set the ivar\n",
    "    continuum_ivar = SNR ** 2 # inverse variance of the noise in the continuum\n",
    "    # now make the noisy fake data\n",
    "    xs = np.arange(x_min - 0.5 * dx, x_max + dx, dx)\n",
    "    ys = np.zeros((N, len(xs)))\n",
    "    y_ivars = np.zeros_like(ys)\n",
    "    bs = np.zeros_like(ys).astype(int)\n",
    "    y_true = true_spectrum(xstar, 0, line_xs, line_ews, sigma_x)\n",
    "    for j in range(N):\n",
    "        ys[j], y_ivars[j] = noisy_true_spectrum(xs, Delta_xs[j], continuum_ivar, line_xs, line_ews, sigma_x)\n",
    "        bs[j], ys[j] = badify(ys[j], badfrac)\n",
    "    return xs, ys, y_ivars, bs, Delta_xs, y_true\n",
    "\n",
    "\n",
    "# Estimate covariances from just one trial:\n",
    "def covariances(resids):\n",
    "    lags = np.arange(12)\n",
    "    var = np.zeros(len(lags)) + np.NaN\n",
    "    var[0] = np.mean(resids * resids)\n",
    "    for lag in lags[1:]:\n",
    "        var[lag] = np.mean(resids[lag:] * resids[:-lag])\n",
    "    return lags, var\n",
    "\n",
    "def get_poorly_sampled_regime_data():\n",
    "    # define high-level parameters, especially including spectrograph parameters\n",
    "    R = 1.35e5 # resolution\n",
    "    sigma_x = 1. / R # LSF sigma in x units\n",
    "    x_min = 8.7000 # minimum ln wavelength\n",
    "    x_max = 8.7025 # maximum ln wavelength\n",
    "    lines_per_x = 2.0e4 # mean density (Poisson rate) of lines per unit ln wavelength\n",
    "    ew_max_x = 3.0e-5 # maximum equivalent width in x units\n",
    "    ew_power = 5.0 # power parameter in EW maker\n",
    "    badfrac = 0.01 # fraction of data to mark bad\n",
    "    # Set the pixel grid and model complexity for the output combined spectrum\n",
    "    dxstar = 1. / R # output pixel grid spacing\n",
    "    xstar = np.arange(x_min + 0.5 * dxstar, x_max, dxstar) # output pixel grid\n",
    "    Mstar = len(xstar) # number of output pixels\n",
    "    P = np.round((x_max - x_min) * R).astype(int) # number of Fourier modes (ish)\n",
    "\n",
    "    # set up the line list for the true spectral model\n",
    "    x_margin = 1.e6/c # hoping no velocities are bigger than 1000 km/s\n",
    "    x_range = x_max - x_min + 2. * x_margin # make lines in a bigger x range than the data range\n",
    "    nlines = np.random.poisson(x_range * lines_per_x) # set the total number of lines\n",
    "    line_xs = (x_min - x_margin) + x_range * np.random.uniform(size=nlines)\n",
    "\n",
    "    # give those lines equivalent widths from a power-law distribution\n",
    "    line_ews = ew_max_x * np.random.uniform(size=nlines) ** ew_power # don't ask\n",
    "\n",
    "    dx1 = 2. / R # pixel spacing in the poorly sampled data; UNDER-SAMPLED!\n",
    "    SNR1 = 18. # s/n ratio per pixel in the continuum\n",
    "    xs1, ys1, y_ivars1, bs1, Delta_xs1, y_true = make_one_dataset(dx1, SNR1, x_min, x_max, line_xs, line_ews, sigma_x, badfrac, xstar)\n",
    "\n",
    "    return (dx1, SNR1, xs1, ys1, y_ivars1, bs1, Delta_xs1, xstar, y_true, line_xs, line_ews, sigma_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_well_sampled_regime_data():\n",
    "    R = 1.35e5 # resolution\n",
    "    sigma_x = 1. / R # LSF sigma in x units\n",
    "    x_min = 8.7000 # minimum ln wavelength\n",
    "    x_max = 8.7025 # maximum ln wavelength\n",
    "    lines_per_x = 2.0e4 # mean density (Poisson rate) of lines per unit ln wavelength\n",
    "    ew_max_x = 3.0e-5 # maximum equivalent width in x units\n",
    "    ew_power = 5.0 # power parameter in EW maker\n",
    "    badfrac = 0.01 # fraction of data to mark bad\n",
    "    # Set the pixel grid and model complexity for the output combined spectrum\n",
    "    dxstar = 1. / R # output pixel grid spacing\n",
    "    xstar = np.arange(x_min + 0.5 * dxstar, x_max, dxstar) # output pixel grid\n",
    "    Mstar = len(xstar) # number of output pixels\n",
    "    P = np.round((x_max - x_min) * R).astype(int) # number of Fourier modes (ish)\n",
    "\n",
    "    # set up the line list for the true spectral model\n",
    "    x_margin = 1.e6/c # hoping no velocities are bigger than 1000 km/s\n",
    "    x_range = x_max - x_min + 2. * x_margin # make lines in a bigger x range than the data range\n",
    "    nlines = np.random.poisson(x_range * lines_per_x) # set the total number of lines\n",
    "    line_xs = (x_min - x_margin) + x_range * np.random.uniform(size=nlines)\n",
    "\n",
    "    # give those lines equivalent widths from a power-law distribution\n",
    "    line_ews = ew_max_x * np.random.uniform(size=nlines) ** ew_power # don't ask\n",
    "\n",
    "    dx2 = 1. / R # pixel spacing in the poorly sampled data; UNDER-SAMPLED!\n",
    "    SNR2 = 12. # s/n ratio per pixel in the continuum\n",
    "    xs2, ys2, y_ivars2, bs2, Delta_xs2, y_true = make_one_dataset(dx2, SNR2,  x_min, x_max, line_xs, line_ews, sigma_x, badfrac, xstar)\n",
    "\n",
    "    return (dx2, SNR2, xs2, ys2, y_ivars2, bs2, Delta_xs2, xstar, y_true, line_xs, line_ews, sigma_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "def wave_to_pixel(wave, wave0):\n",
    "    \"\"\"convert wavelength to pixel given wavelength array\n",
    "    Args :\n",
    "       wave(s) : wavelength(s) (\\AA) to get pixel of\n",
    "       wave0 : array with wavelength as a function of pixel number\n",
    "    Returns :\n",
    "       pixel(s) in the chip\n",
    "    \"\"\"\n",
    "    pix0 = np.arange(len(wave0))\n",
    "    # Need to sort into ascending order\n",
    "    sindx = np.argsort(wave0)\n",
    "    wave0 = wave0[sindx]\n",
    "    pix0 = pix0[sindx]\n",
    "    # Start from a linear baseline\n",
    "    baseline = np.polynomial.Polynomial.fit(wave0, pix0, 1)\n",
    "    ip = interpolate.InterpolatedUnivariateSpline(wave0, pix0 / baseline(wave0), k=3)\n",
    "    out = baseline(wave) * ip(wave)\n",
    "    # NaN for out of bounds\n",
    "    out[wave > wave0[-1]] = np.nan\n",
    "    out[wave < wave0[0]] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def sincint(x, nres, speclist):\n",
    "    \"\"\"Use sinc interpolation to get resampled values\n",
    "    x : desired positions\n",
    "    nres : number of pixels per resolution element (2=Nyquist)\n",
    "    speclist : list of [quantity, variance] pairs (variance can be None)\n",
    "\n",
    "    NOTE: This takes in variance, but returns ERROR.\n",
    "    \"\"\"\n",
    "\n",
    "    dampfac = 3.25 * nres / 2.0\n",
    "    ksize = int(21 * nres / 2.0)\n",
    "    if ksize % 2 == 0:\n",
    "        ksize += 1\n",
    "    nhalf = ksize // 2\n",
    "\n",
    "    # number of output and input pixels\n",
    "    nx = len(x)\n",
    "    nf = len(speclist[0][0])\n",
    "\n",
    "    # integer and fractional pixel location of each output pixel\n",
    "    ix = x.astype(int)\n",
    "    fx = x - ix\n",
    "\n",
    "    # outputs\n",
    "    outlist = []\n",
    "    for spec in speclist:\n",
    "        if spec[1] is None:\n",
    "            outlist.append([np.full_like(x, 0), None])\n",
    "        else:\n",
    "            outlist.append([np.full_like(x, 0), np.full_like(x, 0)])\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        xkernel = np.arange(ksize) - nhalf - fx[i]\n",
    "        # in units of Nyquist\n",
    "        xkernel /= nres / 2.0\n",
    "        u1 = xkernel / dampfac\n",
    "        u2 = np.pi * xkernel\n",
    "        sinc = np.exp(-(u1**2)) * np.sin(u2) / u2\n",
    "        sinc /= nres / 2.0\n",
    "\n",
    "        # the sinc function value at x = 0 is defined by the limit, -> 1\n",
    "        sinc[u2 == 0] = 1\n",
    "\n",
    "        lobe = np.arange(ksize) - nhalf + ix[i]\n",
    "        vals = np.zeros(ksize)\n",
    "        gd = np.where((lobe >= 0) & (lobe < nf))[0]\n",
    "\n",
    "        for spec, out in zip(speclist, outlist):\n",
    "            vals = spec[0][lobe[gd]]\n",
    "            out[0][i] = (sinc[gd] * vals).sum()\n",
    "            if spec[1] is not None:\n",
    "                var = spec[1][lobe[gd]]\n",
    "                out[1][i] = (sinc[gd] ** 2 * var).sum()\n",
    "\n",
    "    for out in outlist:\n",
    "        if out[1] is not None:\n",
    "            out[1] = np.sqrt(out[1])\n",
    "\n",
    "    return outlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "(dx1, SNR1, xs1, ys1, y_ivars1, bs1, Delta_xs1, xstar, y_true, line_xs, line_ews, sigma_x) = get_poorly_sampled_regime_data()\n",
    "\n",
    "    \n",
    "M1 = len(xs1)\n",
    "N1 = len(ys1)\n",
    "name1 = \"poorly sampled input\"\n",
    "print(name1, N1, M1, SNR1)\n",
    "\n",
    "x = []\n",
    "for delta_xs in Delta_xs1:\n",
    "    x.extend(xs1 - delta_xs)\n",
    "\n",
    "x = np.array(x)\n",
    "y = ys1.flatten()\n",
    "\n",
    "spec_errs = np.sqrt(1. / y_ivars1).flatten()\n",
    "mask = ~(bs1.flatten() != 1)\n",
    "\n",
    "spectres_flux, spectres_e_flux = spectres(xstar, x[mask], y[mask], spec_errs=spec_errs[mask])\n",
    "\n",
    "sincint_flux = np.nan * np.ones((ys1.shape[0], xstar.size), dtype=float)\n",
    "sincint_e_flux = np.nan * np.ones((ys1.shape[0], xstar.size), dtype=float)\n",
    "\n",
    "\n",
    "for i in range(ys1.shape[0]):\n",
    "\n",
    "    mask = ~(bs1[i] != 1)\n",
    "\n",
    "    pixel = wave_to_pixel(xstar, xs1 - Delta_xs1[i])\n",
    "    \n",
    "    y_var = 1/y_ivars1[i].copy()\n",
    "    finite = np.isfinite(pixel)\n",
    "\n",
    "    yh = ys1[i].copy()\n",
    "    yh[~mask] = 1\n",
    "    y_var[~mask] = 1e30\n",
    "\n",
    "    ((sincint_flux_, sincint_e_flux_), ) = sincint(\n",
    "        pixel[finite], 2.0, [\n",
    "            [yh, y_var]\n",
    "        ]\n",
    "    )\n",
    "    sincint_flux[i, finite] = sincint_flux_\n",
    "    sincint_e_flux[i, finite] = sincint_e_flux_\n",
    "\n",
    "sincint_ivar = sincint_e_flux**-2\n",
    "sincint_ivar[~np.isfinite(sincint_ivar)] = 0\n",
    "sum_sincint_flux = np.sum(sincint_flux * sincint_ivar, axis=0) / np.sum(sincint_ivar, axis=0)\n",
    "\n",
    "y_star, Cinv_star, _ = resample_spectrum(xstar, x, ys1.flatten(), y_ivars1.flatten(), mask=(bs1.flatten() != 1))\n",
    "\n",
    "z = (y_star - y_true) * np.sqrt(Cinv_star)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.plot(xstar, y_star, c='tab:green')\n",
    "ax.plot(xstar, spectres_flux - y_true, c=\"tab:orange\")\n",
    "ax.plot(xstar, sum_sincint_flux - y_true, c=\"tab:red\")\n",
    "ax.plot(xstar, spectres_flux, c=\"tab:orange\", label=\"SpectRes (arXiv:1705.05165)\")\n",
    "ax.plot(xstar, sum_sincint_flux, c=\"tab:red\", label=\"sincint\")\n",
    "ax.plot(xstar, y_true, c=\"tab:blue\", label=\"Truth\")\n",
    "ax.plot(xstar, y_star - y_true, c=\"tab:green\", label=\"Forward Model(tm)\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for i, xs in enumerate(Delta_xs1):\n",
    "    ax.plot(xs1 - xs, ys1[i] + i + 1, c='#666666')\n",
    "    ax.plot(xstar, sincint_flux[i] + i + 1, c=\"tab:red\")\n",
    "'''\n",
    "#ax.set_ylim(-0.25, 11)#1.25)\n",
    "ax.set_ylim(-0.25, 1.25)\n",
    "\n",
    "ax.set_xlabel(\"log lambda\")\n",
    "ax.set_ylabel(\"flux [-]\")\n",
    "ax.legend()\n",
    "ax.set_title(name)\n",
    "    \n",
    "#assert np.abs(np.mean(z)) < 0.15\n",
    "#assert np.abs(np.std(z) - 1) < 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "\n",
    "(dx1, SNR1, xs1, ys1, y_ivars1, bs1, Delta_xs1, xstar, y_true, line_xs, line_ews, sigma_x) = get_well_sampled_regime_data()\n",
    "\n",
    "    \n",
    "M1 = len(xs1)\n",
    "N1 = len(ys1)\n",
    "name1 = \"well sampled input\"\n",
    "print(name1, N1, M1, SNR1)\n",
    "\n",
    "x = []\n",
    "for delta_xs in Delta_xs1:\n",
    "    x.extend(xs1 - delta_xs)\n",
    "\n",
    "x = np.array(x)\n",
    "y = ys1.flatten()\n",
    "\n",
    "spec_errs = np.sqrt(1. / y_ivars1).flatten()\n",
    "mask = ~(bs1.flatten() != 1)\n",
    "\n",
    "spectres_flux, spectres_e_flux = spectres(xstar, x[mask], y[mask], spec_errs=spec_errs[mask])\n",
    "\n",
    "def do_sincint(xstar, xs1, Delta_xs1, ys1, y_ivars1, bs1):\n",
    "        \n",
    "    sincint_flux = np.nan * np.ones((ys1.shape[0], xstar.size), dtype=float)\n",
    "    sincint_e_flux = np.nan * np.ones((ys1.shape[0], xstar.size), dtype=float)\n",
    "\n",
    "\n",
    "    for i in range(ys1.shape[0]):\n",
    "\n",
    "        mask = ~(bs1[i] != 1)\n",
    "\n",
    "        pixel = wave_to_pixel(xstar, xs1 - Delta_xs1[i])\n",
    "        \n",
    "        y_var = 1/y_ivars1[i].copy()\n",
    "        finite = np.isfinite(pixel)\n",
    "\n",
    "        yh = ys1[i].copy()\n",
    "        yh[~mask] = 1\n",
    "        y_var[~mask] = 1e30\n",
    "\n",
    "        ((sincint_flux_, sincint_e_flux_), ) = sincint(\n",
    "            pixel[finite], 2.0, [\n",
    "                [yh, y_var]\n",
    "            ]\n",
    "        )\n",
    "        sincint_flux[i, finite] = sincint_flux_\n",
    "        sincint_e_flux[i, finite] = sincint_e_flux_\n",
    "\n",
    "    sincint_ivar = sincint_e_flux**-2\n",
    "    sincint_ivar[~np.isfinite(sincint_ivar)] = 0\n",
    "    sum_sincint_flux = np.sum(sincint_flux * sincint_ivar, axis=0) / np.sum(sincint_ivar, axis=0)\n",
    "\n",
    "    return sum_sincint_flux\n",
    "\n",
    "\n",
    "sum_sincint_flux = do_sincint(xstar, xs1, Delta_xs1, ys1, y_ivars1, bs1)\n",
    "\n",
    "y_star, Cinv_star, _ = resample_spectrum(xstar, x, ys1.flatten(), y_ivars1.flatten(), mask=(bs1.flatten() != 1))\n",
    "\n",
    "z = (y_star - y_true) * np.sqrt(Cinv_star)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.plot(xstar, y_star, c='tab:green')\n",
    "ax.plot(xstar, spectres_flux - y_true, c=\"tab:orange\")\n",
    "ax.plot(xstar, sum_sincint_flux - y_true, c=\"tab:red\")\n",
    "ax.plot(xstar, spectres_flux, c=\"tab:orange\", label=\"SpectRes (arXiv:1705.05165)\")\n",
    "ax.plot(xstar, sum_sincint_flux, c=\"tab:red\", label=\"sincint\")\n",
    "ax.plot(xstar, y_true, c=\"tab:blue\", label=\"Truth\")\n",
    "ax.plot(xstar, y_star - y_true, c=\"tab:green\", label=\"Forward Model(tm)\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for i, xs in enumerate(Delta_xs1):\n",
    "    ax.plot(xs1 - xs, ys1[i] + i + 1, c='#666666')\n",
    "    ax.plot(xstar, sincint_flux[i] + i + 1, c=\"tab:red\")\n",
    "'''\n",
    "#ax.set_ylim(-0.25, 11)#1.25)\n",
    "ax.set_ylim(-0.25, 1.25)\n",
    "\n",
    "ax.set_xlabel(\"log lambda\")\n",
    "ax.set_ylabel(\"flux [-]\")\n",
    "ax.legend()\n",
    "ax.set_title(name1)\n",
    "    \n",
    "#assert np.abs(np.mean(z)) < 0.15\n",
    "#assert np.abs(np.std(z) - 1) < 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate using multiple repeated experiments\n",
    "#(dx1, SNR1, xs1, ys1, y_ivars1, bs1, Delta_xs1, xstar, y_true1, line_xs, line_ews, sigma_x) = get_poorly_sampled_regime_data()\n",
    "#(dx2, SNR2, xs2, ys2, y_ivars2, bs2, Delta_xs2, xstar, y_true2, line_xs, line_ews, sigma_x) = get_well_sampled_regime_data()\n",
    "R = 1.35e5 # resolution\n",
    "sigma_x = 1. / R # LSF sigma in x units\n",
    "x_min = 8.7000 # minimum ln wavelength\n",
    "x_max = 8.7025 # maximum ln wavelength\n",
    "lines_per_x = 2.0e4 # mean density (Poisson rate) of lines per unit ln wavelength\n",
    "ew_max_x = 3.0e-5 # maximum equivalent width in x units\n",
    "ew_power = 5.0 # power parameter in EW maker\n",
    "badfrac = 0.01 # fraction of data to mark bad\n",
    "# Set the pixel grid and model complexity for the output combined spectrum\n",
    "dxstar = 1. / R # output pixel grid spacing\n",
    "xstar = np.arange(x_min + 0.5 * dxstar, x_max, dxstar) # output pixel grid\n",
    "Mstar = len(xstar) # number of output pixels\n",
    "P = np.round((x_max - x_min) * R).astype(int) # number of Fourier modes (ish)\n",
    "\n",
    "# set up the line list for the true spectral model\n",
    "x_margin = 1.e6/c # hoping no velocities are bigger than 1000 km/s\n",
    "x_range = x_max - x_min + 2. * x_margin # make lines in a bigger x range than the data range\n",
    "nlines = np.random.poisson(x_range * lines_per_x) # set the total number of lines\n",
    "line_xs = (x_min - x_margin) + x_range * np.random.uniform(size=nlines)\n",
    "\n",
    "# give those lines equivalent widths from a power-law distribution\n",
    "line_ews = ew_max_x * np.random.uniform(size=nlines) ** ew_power # don't ask\n",
    "dx1 = 2. / R # pixel spacing in the poorly sampled data; UNDER-SAMPLED!\n",
    "SNR1 = 18. # s/n ratio per pixel in the continuum\n",
    "dx2 = 1. / R # pixel spacing in the poorly sampled data; UNDER-SAMPLED!\n",
    "SNR2 = 12. # s/n ratio per pixel in the continuum\n",
    "\n",
    "name1 = \"poorly sampled input\"\n",
    "name2 = \"well sampled input\"\n",
    "ntrial = 64\n",
    "for i, dx, SNR in [(1, dx1, SNR1),\n",
    "                (2, dx2, SNR2)]:\n",
    "    numerator = 0.\n",
    "    numerator_sp = 0.\n",
    "    for trial in range(ntrial):\n",
    "        xs, ys, y_ivars, bs, Delta_xs, y_true = make_one_dataset(dx, SNR, x_min, x_max, line_xs, line_ews, sigma_x, badfrac, xstar)\n",
    "        x = []\n",
    "        for delta_xs in Delta_xs:\n",
    "            x.extend(xs - delta_xs)\n",
    "\n",
    "        y_star, Cinv_star, _ = resample_spectrum(xstar, x, ys.flatten(), y_ivars.flatten(), mask=(bs.flatten() != 1))\n",
    "\n",
    "        #ystar_sp, foo, bar = Standard_Practice_tm(xs, ys, bs, Delta_xs, xstar)\n",
    "        ystar_sp = do_sincint(xstar, xs, Delta_xs, ys, y_ivars, bs)\n",
    "        \n",
    "        lags, covars = covariances(y_star - y_true)\n",
    "        # sometimes standard practice will have nans at the edge\n",
    "        finite_sp = ystar_sp - y_true\n",
    "        lags, covars_sp = covariances((ystar_sp - y_true)[np.isfinite(finite_sp)])\n",
    "        assert np.all(np.isfinite(covars_sp))\n",
    "        assert np.all(np.isfinite(covars))\n",
    "\n",
    "        numerator += covars\n",
    "        numerator_sp += covars_sp\n",
    "\n",
    "    if i == 1:\n",
    "        covars1 = numerator / ntrial\n",
    "        covars_sp1 = numerator_sp / ntrial\n",
    "    elif i == 2:\n",
    "        covars2 = numerator / ntrial\n",
    "        covars_sp2 = numerator_sp / ntrial    \n",
    "\n",
    "# the forward model should have a lower mean covariance\n",
    "#assert np.mean(np.abs(covars1)[1:]) < np.mean(np.abs(covars_sp1)[1:])\n",
    "#assert np.mean(np.abs(covars2)[1:]) < np.mean(np.abs(covars_sp2)[1:])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axhline(0., color=\"k\", lw=0.5)\n",
    "ax.plot(lags, covars1, \"ko\", ms=5,\n",
    "        label=\"Forward Model (tm), \" + name1)\n",
    "ax.plot(lags, covars_sp1, \"ko\", ms=5, mfc=\"none\",\n",
    "        label=\"sincint, \" + name1)\n",
    "ax.plot(lags, covars2, \"ko\", ms=10, alpha=0.5, mec=\"none\",\n",
    "        label=\"Forward Model (tm), \" + name2)\n",
    "ax.plot(lags, covars_sp2, \"ko\", ms=10, alpha=0.5, mfc=\"none\",\n",
    "        label=\"sincint, \" + name2)\n",
    "fig.legend()\n",
    "ax.set_xlabel(\"lag (in output pixels)\")\n",
    "ax.set_ylabel(\"covariance (squared-flux units)\")\n",
    "ax.set_title(\"covariances estimated from {} trials\".format(ntrial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
