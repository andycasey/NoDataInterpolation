\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}

% page and document setup
\usepackage[letterpaper]{geometry}
\addtolength{\topmargin}{-0.7in}
\addtolength{\textheight}{1.8in}
\renewcommand{\paragraph}[1]{\medskip\par\noindent\textbf{#1}~---}

% text macros
\newcommand{\sectionname}{Section}

\title{\bfseries%
Don't interpolate your data!}
\author{Hogg, Casey, Daunt, others?}
\date{October 2022}

\sloppy\sloppypar\raggedbottom\frenchspacing
\begin{document}

\maketitle

\paragraph{Abstract}
When there are many observations of an astronomical source---many images with different dithers, or many spectra taken at different barycentric velocities---it is often tempting to shift and stack the data, to (for example) make a high signal-to-noise average image or mean spectrum.
Bound-saturating measurements are made not by manipulating data, but instead by optimizing (or otherwise using) 
a likelihood function, where the data are treated as fixed, and model parameters are modified to fit the data.
Traditional shifting and stacking of data can be converted into a model-fitting procedure, such that no data are ever harmed.
The key component of this conversion is a spectral model that is a continuous function of wavelength (or position in the case of imaging) that can represent the psf- and pixel-convolved signal being measured by the device after any reasonable translation.
The benefits of a modeling approach are myriad:
The sacred and expensive data never have to be interpolated or otherwise modified.
Noise maps, data gaps, and bad-data masks, none of which can easily be interpolated, don't have to be manipulated either.
The simplest model-fitting procedure, like the original shift-and-add procedure, is linear in the data, so noise propagation is straightforward.
The only cost is a small increase in computational complexity.
We demonstrate all these things with toy data; we provide open-source sample code for re-use.

\section{Introduction}

Hello World!

\section{Concepts and assumptions}

What we do here can apply to almost any astronomical signals, but we are going to specialize to astronomical spectra for specificity.
We are going to make many other assumptions too, all of which are discussed in this \sectionname.

\paragraph{Multi-epoch spectra with shifts}
We will assume that there are $n$ observations (epochs) of the same star (or maybe of different stars or quasars, say, that are assumed to be more-or-less identical, intrinsically, but let's think of a single star for now).
Each of these observations $i$ (with $1\leq i\leq n$) produces a one-dimensional observed (noisy) image $y_i$.
The $y_i$ can be thought of as $m_i$-vectors in what follows, where $m_i$ is the number of pixels in the spectrum.
The different observations are made at different relative velocities (star minus spectrograph) such that the different images are shifted by a different shift $\Delta x_i$ relative to the detector or extracted wavelength grid.

\paragraph{Shift operators}
Because the shifts might be non-linear, the shifts $\Delta x_i$ won't be pure numbers but something more like shift operators.
That is, if there were a true spectrum $\tilde{y}$, each individual noisy image $y_i$ would be related to that true spectrum by a shift operator acting on that true spectrum, plus noise.
We will begin by assuming that (from some external information) we know these shift operators very accurately.
At the end we may (do we?) return to the question of how those shift operators are determined.

\paragraph{Wavelength calibration}
We will assume that, for every $m_i$-pixel image $y_i$ we also have a $m_i$-vector (or list) $x_i$ of pixel positions, such that each element of $x_i$ gives an accurate and precise value for the wavelength (or position in the spectrograph, in some settings) for each pixel of the image $y_i$.
That is, the device is well calibrated, and we know all the housekeeping data we need for image $y_i$.

\paragraph{Noise model}
Each observation is noisy.
We will assume that the noise has known properties, and especially that it is additive, (nearly) zero-mean and (nearly) Gaussian in form, with known variance.
Under these assumptions, each spectrum $y_i$ has an associated variance tensor $C_i$.
If $y_i$ is an $m_i$-vector, then $C_i$ is a nonnegative-definite $m_i\times m_i$ 2-tensor.
We don't need to assume that the different pixels of the spectrum received independent noise, but we do assume that each epoch $i$ has an independent noise draw.

\paragraph{Bad-pixel masks}
Occasionally (or frequently) some of the pixels of a spectrum $y_i$ might be bad---affected by cosmic rays or electronics issues---such that there is a bad-pixel mask $b_i$ associated with each spectrum $y_i$.
This mask has value 1 in the locations in all good pixels, and 0 in the locations of all bad pixels.

\paragraph{Data gaps}
There is no assumption here that all the $y_i$ have the same number of pixels $m_i$, nor that the pixel grid is in any sense uniform or complete.
That is, there can be gaps and spaces in the wavelength coverage of the spectra, as there are at chip gaps and where the detector has bad columns.

\paragraph{Pixel-convolved line-spread function}
The spectrograph has something like a point-spread function or line-spread function, which, in the case of spectrosccopy, sets the shape of an unresolved spectral line.
In general it depends on the slit or fiber width, the spectrograph resolution and optics, instrument focus, and the properties of the detector.
In what follows we will not build any model of any of this.
Instead we will assume that there is a relatively constant pixel-convolved line-spread function (PCLSF), constant both in time, and constant with respect to the shifts $\Delta x_i$ we see in our data set.
We consider only the PCLSF, because then the sampling by the detector pixels does not require any additional convolution.
That is, when the PCLSF is used to model a spectrum, the projection onto the pixels is just a sampling of the function at the pixel centers, and does not involve any convolution over the face of the pixel.
All that said, we won't explicitly model or use the PCLSF in what follows; we will just assume that our continuous spectral model is a model for the pixel-convolved, finite-resolution spectrum; we won't be doing any convolutions in comparing models and data.

\paragraph{Continuous spectral model}
In what follows we are going to avoid interpolating the \emph{data} by having a spectral \emph{model} that can be arbitrarily and losslessly interpolated.
That means that the spectral model must be a representation of a continuous one-dimensional function.
If we were working on two-dimensional images, the model would have to be a representation of a continous two-dimensional function.

\paragraph{Linear basis or mixture models}
The simplest kind of model for a continuous function is a sum or mixture or linear combination of continuous basis functions.
These could be sines and cosines for a Fourier series model.
They could be spline (or sinc or Lanczos) cardinal basis functions.
They could be wavelets.
The point is that if we use a linear basis, and assume that noises are Gaussian, we will get closed-form expressions for the data combination.
Thus we will use a linear basis.

\paragraph{Band limit}
We say that a signal is \emph{band-limited} if it has no frequency content above some highest possible cutoff frequency.
There is a weird sense in which data from a spectrograph both is, and is not, band limited.
It is band limited in that the spectrograph is finite in resolution, such that no real spectroscopic signal can show features narrower than the PCLSF.
It is not band-limited in that the photon noise in the device is independent (or close to independent) from pixel to pixel, such that the noise contribution to each observation $y_i$ has support at all spatial frequencies.

One interesting question in what follows is whether the forward model we build for the data should itself be restricted to the band limit defined by the spectrograph resolution, or whether it should permit higher frequencies.
It might surprise the reader to learn that we prefer to let the model capture higher frequencies, even when we think they shouldn't be there for any reasons other than noise, given the hardware.
More on this below.

\paragraph{Critical sampling}
Because of considerations related to the Nyquist frequency on a uniform grid, it is valuable for a spectrograph to have a pixel spacing on the device that is smaller than the width of the PCLSF.
Specifically, it is valuable for there to be two or three pixels across the full-width at half-maximum (FWHM) of the PCLSF.
This keeps the band-limited part of the spectroscopic signal well-sampled in the data.
Spectrographs that don't have pixel scales this fine sometimes do clever things to dither \cite{apogeehardware}.

\paragraph{Non-uniform fast Fourier transform}
In the special case that the spectral model is a Fourier series, there are very useful and fast tools for interpolation, including especially the non-uniform fast Fourier transform (for example, \cite{finufft}).

\paragraph{Time variability}
When we average data (or build a static model of multi-epoch data), we are implicitly assuming that there is no intrinsic variability to the source being observed.
That is, we are assuming that the changes from observation to observation are solely from either the shifts $\Delta x_i$ or from the noise.
We interpolate the model to account for the shifts, and we combine data to beat down the noise.
There are situations in which there is substantial time variability and these approaches are still valid, and there are modified approaches.
We will discuss these changes and generalizations at the end.

\paragraph{Bias, sky, tellurics, flat-field}
In what follows, we will assume that the input data are well calibrated in various ways.
In particular, we will assume that the images or spectra have been bias-corrected, sky-subtracted, flat-fielded, and tellurics-corrected sufficiently well that the different observations $y_i$ can be seen as observations of the same underlying or intrinsic signal.

\section{Method}

\section{Toy experiments and results}

\section{Discussion}

Give some summary of the above.

What happens if you don't know your shifts?

What happens if you have multiple shifting signals?
\texttt{wobble} \cite{wobble} is a solution to one version of that problem.

Discuss time-variable inputs, and how you would modify to deal with that.
One way involves modeling the time variability with some process.
Another way involves ignoring it and just getting the average anyway!

What about non-Gaussian noise?

What about data from different instruments with different LSFs / PSFs? What about data with different pixel scales?

\end{document}
